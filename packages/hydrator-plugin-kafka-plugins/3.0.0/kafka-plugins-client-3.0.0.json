{
  "properties": {
    "doc.KAFKAWRITER-SINK": "[![Build Status](https://travis-ci.org/hydrator/kafka-plugins.svg?branch=master)](https://travis-ci.org/hydrator/kafka-plugins) [![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n\nKafka Sink\n==========\n\nKafka sink that allows you to write events into CSV or JSON to kafka. Plugin has the capability to push the data to one or more Kafka topics. \nIt can use one of the field values from input to partition the data on topic. The sink can also be configured to operate in either sync or async mode. \nThe sink also allows you to write events into kerberos-enabled kafka.\n\n<img align=\"center\" src=\"kafka-sink-plugin-config.png\"  width=\"400\" alt=\"plugin configuration\" />\n\nUsage Notes\n-----------\n\nKafka sink emits events in realtime to configured kafka topic and partition. It uses kafka producer [2.6 apis](https://kafka.apache.org/26/documentation.html) to write events into kafka.\n\nThis sink can be configured to operate in synchronous or asynchronous mode. In synchronous mode, each event will be sent to the broker synchronously on the thread that calls it. This is not sufficient on most of the high volume environments. \nIn async mode, the kafka producer will batch together all the kafka events for greater throughput. But that makes it open for the possibility of dropping unsent events in case of client machine failure. Since kafka producer by default uses synchronous mode, this sink also uses Synchronous producer by default.\n\nIt uses String partitioner and String serializer for key and value to write events to kafka. Optionally if kafka key is provided, producer will use that key to partition events accross multiple partitions in a given topic. This sink also allows compression configuration. By default compression is none.\n\nKafka producer can be tuned using many properties as shown [here](https://kafka.apache.org/26/documentation.html#producerconfigs). This sink allows user to configure any property supported by kafka 2.6 Producer.\n\n\nPlugin Configuration\n---------------------\n\n| Configuration | Required | Default | Description |\n| :------------ | :------: | :----- | :---------- |\n| **Kafka Brokers** | **Y** | N/A | List of Kafka brokers specified in host1:port1,host2:port2 form. |\n| **Kafka Topic** | **Y** | N/A | The Kafka topic to write to. This should be a valid kafka topic string. Kafka topic should already exist. |\n| **Is Async** | **Y** | False | Specifies whether writing the events to broker is *Asynchronous* or *Synchronous*.  |\n| **Compression Type** | **Y** | none | This configuration specifies the format of the event published to Kafka. |\n| **Kerberos Principal** | **N** | N/A | The kerberos principal used for the source when kerberos security is enabled for kafka. |\n| **Keytab Location** | **N** | N/A | The keytab location for the kerberos principal when kerberos security is enabled for kafka. |\n| **Additional Kafka Producer Properties** | **N** | N/A | Specifies additional kafka producer properties like acks, client.id as key and value pair. |\n| **Message Format** | **Y** | CSV | This configuration specifies serialization format of the event published to Kafka. |\n| **Message Key Field** | **N** | N/A | This configuration specifies the input field that should be used as the key for the event published into Kafka. This field will be used to partition kafka events across multiple partitions of a topic. Key field should be of type string. |\n\n\nBuild\n-----\nTo build this plugin:\n\n```\n   mvn clean package\n```    \n\nThe build will create a .jar and .json file under the ``target`` directory.\nThese files can be used to deploy your plugins.\n\nDeployment\n----------\nYou can deploy your plugins using the CDAP CLI:\n\n    > load artifact <target/kafka-plugins-<version>.jar config-file <target/kafka-plugins<version>.json>\n\nFor example, if your artifact is named 'kafka-plugins-<version>':\n\n    > load artifact target/kafka-plugins-<version>.jar config-file target/kafka-plugins-<version>.json\n    \n## Mailing Lists\n\nCDAP User Group and Development Discussions:\n\n* `cdap-user@googlegroups.com <https://groups.google.com/d/forum/cdap-user>`\n\nThe *cdap-user* mailing list is primarily for users using the product to develop\napplications or building plugins for appplications. You can expect questions from \nusers, release announcements, and any other discussions that we think will be helpful \nto the users.\n\n## License and Trademarks\n\nCopyright Â© 2017 Cask Data, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except\nin compliance with the License. You may obtain a copy of the License at\n\nhttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software distributed under the \nLicense is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, \neither express or implied. See the License for the specific language governing permissions \nand limitations under the License.\n\nCask is a trademark of Cask Data, Inc. All rights reserved.\n\nApache, Apache HBase, and HBase are trademarks of The Apache Software Foundation. Used with\npermission. No endorsement by The Apache Software Foundation is implied by the use of these marks.      \n",
    "doc.KafkaAlerts-alertpublisher": "# Kafka Alert Publisher\n\n\nDescription\n-----------\nKafka Alert Publisher that allows you to publish alerts to kafka as json objects.\nThe plugin internally uses kafka producer apis to publish alerts. \nThe plugin allows to specify kafka topic to use for publishing and other additional\nkafka producer properties. This plugin uses kafka 2.6 java apis.\n\n\nConfiguration\n-------------\n**brokers:** List of Kafka brokers specified in host1:port1,host2:port2 form.\n\n**topic:** The Kafka topic to write to. This topic should already exist in kafka.\n\n**producerProperties** Specifies additional kafka producer properties like acks, client.id as key and value pair.\n\n**Kerberos Principal** The kerberos principal used for the source when kerberos security is enabled for kafka.\n\n**Keytab Location** The keytab location for the kerberos principal when kerberos security is enabled for kafka.\n\nExample\n-------\nThis example publishes alerts to already existing kafka topic alarm as json objects.\nThe kafka broker is running at localhost and port 9092. Additional kafka producer properties \nare like acks and client.id are specified as well.\n\n```json\n{\n    \"name\": \"Kafka\",\n    \"type\": \"alertpublisher\",\n    \"properties\": {\n        \"brokers\": \"localhost:9092\",\n        \"topic\": \"alarm\",\n        \"producerProperties\": \"acks:2,client.id:myclient\"\n    }\n}\n```\n",
    "widgets.Kafka-batchsource": "{\n  \"outputs\": [{\n    \"name\": \"schema\",\n    \"widget-type\": \"schema\",\n    \"widget-attributes\": {\n      \"default-schema\": {\n        \"name\": \"etlSchemaBody\",\n        \"type\": \"record\",\n        \"fields\": [{\n          \"name\": \"message\",\n          \"type\": \"string\"\n        }]\n      },\n      \"schema-default-type\": \"string\",\n      \"property-watch\": \"format\"\n    }\n  }],\n  \"jump-config\": {\"datasets\": [{\"ref-property-name\": \"referenceName\"}]},\n  \"metadata\": {\"spec-version\": \"1.5\"},\n  \"configuration-groups\": [\n    {\n      \"label\": \"Connection\",\n      \"properties\": [\n        {\n          \"widget-type\": \"toggle\",\n          \"name\": \"useConnection\",\n          \"label\": \"Use Connection\",\n          \"widget-attributes\": {\n            \"default\": \"false\",\n            \"off\": {\n              \"label\": \"NO\",\n              \"value\": \"false\"\n            },\n            \"on\": {\n              \"label\": \"YES\",\n              \"value\": \"true\"\n            }\n          }\n        },\n        {\n          \"widget-type\": \"connection-select\",\n          \"name\": \"connection\",\n          \"label\": \"Connection\",\n          \"widget-attributes\": {\"connectionType\": \"Kafka\"}\n        },\n        {\n          \"widget-type\": \"csv\",\n          \"name\": \"kafkaBrokers\",\n          \"label\": \"Kafka Brokers\",\n          \"widget-attributes\": {\"delimiter\": \",\"}\n        }\n      ]\n    },\n    {\n      \"label\": \"Kafka Configuration\",\n      \"properties\": [\n        {\n          \"widget-type\": \"textbox\",\n          \"name\": \"referenceName\",\n          \"label\": \"Reference Name\"\n        },\n        {\n          \"widget-type\": \"connection-browser\",\n          \"widget-category\": \"plugin\",\n          \"widget-attributes\": {\n            \"label\": \"Browse\",\n            \"connectionType\": \"KAFKA\"\n          }\n        },\n        {\n          \"widget-type\": \"textbox\",\n          \"name\": \"topic\",\n          \"label\": \"Kafka Topic\"\n        },\n        {\n          \"widget-type\": \"textbox\",\n          \"name\": \"offsetDir\",\n          \"label\": \"Offset Directory\"\n        },\n        {\n          \"widget-type\": \"csv\",\n          \"name\": \"partitions\",\n          \"label\": \"Topic Partitions\",\n          \"widget-attributes\": {\"delimiter\": \",\"}\n        },\n        {\n          \"widget-type\": \"keyvalue\",\n          \"name\": \"initialPartitionOffsets\",\n          \"label\": \"Initial Offsets\",\n          \"widget-attributes\": {\n            \"key-placeholder\": \"Partition\",\n            \"value-placeholder\": \"Offset\",\n            \"showDelimiter\": \"false\"\n          }\n        },\n        {\n          \"widget-type\": \"textbox\",\n          \"name\": \"keyField\",\n          \"label\": \"Key Field\"\n        },\n        {\n          \"widget-type\": \"textbox\",\n          \"name\": \"partitionField\",\n          \"label\": \"Partition Field\"\n        },\n        {\n          \"widget-type\": \"textbox\",\n          \"name\": \"offsetField\",\n          \"label\": \"Offset Field\"\n        },\n        {\n          \"widget-type\": \"textbox\",\n          \"name\": \"maxNumberRecords\",\n          \"label\": \"Max Number Records\"\n        },\n        {\n          \"widget-type\": \"keyvalue\",\n          \"name\": \"kafkaProperties\",\n          \"label\": \"Additional Kafka Consumer Properties\",\n          \"widget-attributes\": {\n            \"key-placeholder\": \"Kafka consumer property\",\n            \"value-placeholder\": \"Kafka consumer property value\",\n            \"showDelimiter\": \"false\"\n          }\n        }\n      ]\n    },\n    {\n      \"label\": \"Format\",\n      \"properties\": [{\n        \"widget-type\": \"select\",\n        \"name\": \"format\",\n        \"label\": \"Format\",\n        \"widget-attributes\": {\n          \"default\": \"\",\n          \"values\": [\n            \"\",\n            \"avro\",\n            \"binary\",\n            \"clf\",\n            \"csv\",\n            \"grok\",\n            \"syslog\",\n            \"text\",\n            \"tsv\"\n          ]\n        }\n      }]\n    },\n    {\n      \"label\": \"Authentication\",\n      \"properties\": [\n        {\n          \"widget-type\": \"textbox\",\n          \"name\": \"principal\",\n          \"label\": \"Kerberos Principal\"\n        },\n        {\n          \"widget-type\": \"textbox\",\n          \"name\": \"keytabLocation\",\n          \"label\": \"Keytab Location\"\n        }\n      ]\n    }\n  ],\n  \"display-name\": \"Kafka Consumer\",\n  \"icon\": {\n    \"arguments\": {\"data\": \"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAYAAAAeP4ixAAAAAXNSR0IArs4c6QAAACBjSFJNAAB6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\\r\\nPGYAAAAASUVORK5C\"},\n    \"type\": \"inline\"\n  },\n  \"filters\": [\n    {\n      \"condition\": {\"expression\": \"useConnection == false\"},\n      \"name\": \"showConnectionProperties \",\n      \"show\": [{\n        \"name\": \"kafkaBrokers\",\n        \"type\": \"property\"\n      }]\n    },\n    {\n      \"condition\": {\"expression\": \"useConnection == true\"},\n      \"name\": \"showConnectionId\",\n      \"show\": [{\n        \"name\": \"connection\",\n        \"type\": \"property\"\n      }]\n    }\n  ]\n}",
    "doc.KAFKABATCHSOURCE": "[![Build Status](https://travis-ci.org/hydrator/kafka-plugins.svg?branch=master)](https://travis-ci.org/hydrator/kafka-plugins) [![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n\nKafka Batch Source\n===========\n\nKafka batch source that emits a records with user specified schema.\n\n<img align=\"center\" src=\"kafka-batch-source-plugins-config.png\"  width=\"400\" alt=\"plugin configuration\" />\n\nUsage Notes\n-----------\n\nKafka Batch Source can be used to read events from a kafka topic. It uses kafka consumer [2.6 apis](https://kafka.apache.org/26/documentation.html) to read events from a kafka topic. The Kafka Batch Source supports providing additional kafka properties for the kafka consumer, reading from kerberos-enabled kafka and limiting the number of records read. Kafka Batch Source converts incoming kafka events into cdap structured records which then can be used for further transformations.\n\nThe source will read from the earliest available offset or the initial offset that specified in the config for the first run, remember the last offset it read last run and continue from that offset for the next run. \n\nPlugin Configuration\n---------------------\n\n| Configuration | Required | Default | Description |\n| :------------ | :------: | :----- | :---------- |\n| **Kafka Brokers** | **Y** | N/A | List of Kafka brokers specified in host1:port1,host2:port2 form. |\n| **Kafka Topic** | **Y** | N/A | The Kafka topic to read from. |\n| **Offset Directory** | **Y** | N/A | A directory path to store the latest Kafka offsets. A file named with the pipeline name will be created under the given directory.\n| **Topic Partition** | **N** | N/A | List of topic partitions to read from. If not specified, all partitions will be read.  |\n| **Initial Partition Offsets** | **N** | N/A | The initial offset for each topic partition. If this is not specified, earliest offset will be used. This offset will only be used for the first run of the pipeline. Any subsequent run will read from the latest offset from previous run.  Offsets are inclusive. If an offset of 5 is used, the message at offset 5 will be read. |\n| **Key Field** | **N** | N/A | Optional name of the field containing the message key. If this is not set, no key field will be added to output records. If set, this field must be present in the schema property and must be bytes. |\n| **Partition Field** | **N** | N/A | Optional name of the field containing the partition the message was read from. If this is not set, no partition field will be added to output records. If set, this field must be present in the schema property and must be an int. |\n| **Offset Field** | **N** | N/A | Optional name of the field containing the partition offset the message was read from. If this is not set, no offset field will be added to output records. If set, this field must be present in the schema property and must be a long. |\n| **Max Number Records** | **N** | N/A | The maximum of messages the source will read from each topic partition. If the current topic partition does not have this number of messages, the source will read to the latest offset. Note that this is an estimation, the acutal number of messages the source read may be smaller than this number. |\n| **Kerberos Principal** | **N** | N/A | The kerberos principal used for the source when kerberos security is enabled for kafka. |\n| **Keytab Location** | **N** | N/A | The keytab location for the kerberos principal when kerberos security is enabled for kafka. |\n| **Additional Kafka Consumer Properties** | **N** | N/A | Additional kafka consumer properties to set. |\n| **Format** | **N** | N/A | Optional format of the Kafka event message. Any format supported by CDAP is supported. For example, a value of 'csv' will attempt to parse Kafka payloads as comma-separated values. If no format is given, Kafka message payloads will be treated as bytes. |\n\n\nBuild\n-----\nTo build this plugin:\n\n```\n   mvn clean package\n```    \n\nThe build will create a .jar and .json file under the ``target`` directory.\nThese files can be used to deploy your plugins.\n\nDeployment\n----------\nYou can deploy your plugins using the CDAP CLI:\n\n    > load artifact <target/kafka-plugins-<version>.jar config-file <target/kafka-plugins<version>.json>\n\nFor example, if your artifact is named 'kafka-plugins-<version>':\n\n    > load artifact target/kafka-plugins-<version>.jar config-file target/kafka-plugins-<version>.json\n    \n## Mailing Lists\n\nCDAP User Group and Development Discussions:\n\n* `cdap-user@googlegroups.com <https://groups.google.com/d/forum/cdap-user>`\n\nThe *cdap-user* mailing list is primarily for users using the product to develop\napplications or building plugins for appplications. You can expect questions from \nusers, release announcements, and any other discussions that we think will be helpful \nto the users.\n\n## License and Trademarks\n\nCopyright Â© 2017 Cask Data, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except\nin compliance with the License. You may obtain a copy of the License at\n\nhttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software distributed under the \nLicense is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, \neither express or implied. See the License for the specific language governing permissions \nand limitations under the License.\n\nCask is a trademark of Cask Data, Inc. All rights reserved.\n\nApache, Apache HBase, and HBase are trademarks of The Apache Software Foundation. Used with\npermission. No endorsement by The Apache Software Foundation is implied by the use of these marks.      \n",
    "doc.Kafka-batchsource": "# Kafka Batch Source\n\n\nDescription\n-----------\nKafka batch source. Emits the record from kafka. It will emit a record based on the schema and format \nyou use, or if no schema or format is specified, the message payload will be emitted. The source will \nremember the offset it read last run and continue from that offset for the next run.\nThe Kafka batch source supports providing additional kafka properties for the kafka consumer, \nreading from kerberos-enabled kafka and limiting the number of records read. This plugin uses kafka 2.6 java apis.\n\nUse Case\n--------\nThis source is used whenever you want to read from Kafka. For example, you may want to read messages\nfrom Kafka and write them to a Table.\n\n\nProperties\n----------\n**Use Connection** Whether to use a connection, if a connection is used, \nthe brokers do not need to be provided.\n\n**Connection** Name of the connection to use, should have the macro function ${conn:(connection-name)} to provide.\n\n**referenceName:** This will be used to uniquely identify this source for lineage, annotating metadata, etc.\n\n**kafkaBrokers:** List of Kafka brokers specified in host1:port1,host2:port2 form. (Macro-enabled)\n\n**topic:** The Kafka topic to read from. (Macro-enabled)\n\n**offsetDir:** Optional directory path to track the latest offset we read from kafka. It is useful for incrementally\nprocessing data from Kafka across subsequent runs. (Macro-enabled)\n\n**partitions:** List of topic partitions to read from. If not specified, all partitions will be read. (Macro-enabled)\n\n**initialPartitionOffsets:** The initial offset for each topic partition. This offset will only be used for the \nfirst run of the pipeline. Any subsequent run will read from the latest offset from previous run. \nOffsets are inclusive. If an offset of 5 is used, the message at offset 5 will be read. (Macro-enabled)\n\n**schema:** Output schema of the source. If you would like the output records to contain a field with the\nKafka message key, the schema must include a field of type bytes or nullable bytes, and you must set the\nkeyField property to that field's name. Similarly, if you would like the output records to contain a field with\nthe timestamp of when the record was read, the schema must include a field of type long or nullable long, and you\nmust set the timeField property to that field's name. Any field that is not the keyField, partitionField and keyField\n will be used in conjuction with the format to parse Kafka message payloads.\n \n**maxNumberRecords** The maximum of messages the source will read from each topic partition. \nIf the current topic partition does not have this number of messages, the source will read to the latest offset. \nNote that this is an estimation, the acutal number of messages the source read may be smaller than this number. \n\n**principal** The kerberos principal used for the source when kerberos security is enabled for kafka.\n \n**keytabLocation** The keytab location for the kerberos principal when kerberos security is enabled for kafka.\n\n**kafkaProperties** Additional kafka consumer properties to set.\n\n**format:** Optional format of the Kafka event message. Any format supported by CDAP is supported.\nFor example, a value of 'csv' will attempt to parse Kafka payloads as comma-separated values.\nIf no format is given, Kafka message payloads will be treated as bytes.\n\n**keyField:** Optional name of the field containing the message key.\nIf this is not set, no key field will be added to output records.\nIf set, this field must be present in the schema property and must be bytes.\n\n**partitionField:** Optional name of the field containing the partition the message was read from.\nIf this is not set, no partition field will be added to output records.\nIf set, this field must be present in the schema property and must be an int.\n\n**offsetField:** Optional name of the field containing the partition offset the message was read from.\nIf this is not set, no offset field will be added to output records.\nIf set, this field must be present in the schema property and must be a long.\n\n\nExample\n-------\nThis example reads from the 'purchases' topic of a Kafka instance running\non brokers host1.example.com:9092 and host2.example.com:9092. The source will add\na field named 'key' which will have the message key in it. It parses the Kafka messages \nusing the 'csv' format with 'user', 'item', 'count', and 'price' as the message schema.\n\n```json\n{\n    \"name\": \"Kafka\",\n    \"type\": \"streamingsource\",\n    \"properties\": {\n        \"topics\": \"purchases\",\n        \"brokers\": \"host1.example.com:9092,host2.example.com:9092\",\n        \"format\": \"csv\",\n        \"keyField\": \"key\",\n        \"schema\": \"{\n            \\\"type\\\":\\\"record\\\",\n            \\\"name\\\":\\\"purchase\\\",\n            \\\"fields\\\":[\n                {\\\"name\\\":\\\"key\\\",\\\"type\\\":\\\"bytes\\\"},\n                {\\\"name\\\":\\\"user\\\",\\\"type\\\":\\\"string\\\"},\n                {\\\"name\\\":\\\"item\\\",\\\"type\\\":\\\"string\\\"},\n                {\\\"name\\\":\\\"count\\\",\\\"type\\\":\\\"int\\\"},\n                {\\\"name\\\":\\\"price\\\",\\\"type\\\":\\\"double\\\"}\n            ]\n        }\"\n    }\n}\n```\n\nFor each Kafka message read, it will output a record with the schema:\n\n| field name  | type             |\n| ----------- | ---------------- |\n| key         | bytes            |\n| user        | string           |\n| item        | string           |\n| count       | int              |\n| price       | double           |\n",
    "widgets.Kafka-connector": "{\n  \"outputs\": [],\n  \"metadata\": {\"spec-version\": \"1.5\"},\n  \"configuration-groups\": [{\n    \"label\": \"Credentials\",\n    \"properties\": [{\n      \"widget-type\": \"csv\",\n      \"name\": \"kafkaBrokers\",\n      \"label\": \"Kafka Brokers\",\n      \"widget-attributes\": {\"delimiter\": \",\"}\n    }]\n  }],\n  \"display-name\": \"Kafka Connector\",\n  \"icon\": {\n    \"arguments\": {\"data\": \"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAYAAAAeP4ixAAAAAXNSR0IArs4c6QAAACBjSFJNAAB6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\\r\\nPGYAAAAASUVORK5C\"},\n    \"type\": \"inline\"\n  }\n}",
    "widgets.Kafka-streamingsource": "{\n  \"outputs\": [{\n    \"name\": \"schema\",\n    \"widget-type\": \"schema\",\n    \"widget-attributes\": {\n      \"default-schema\": {\n        \"name\": \"etlSchemaBody\",\n        \"type\": \"record\",\n        \"fields\": [{\n          \"name\": \"message\",\n          \"type\": \"string\"\n        }]\n      },\n      \"schema-default-type\": \"string\",\n      \"property-watch\": \"format\"\n    }\n  }],\n  \"jump-config\": {\"datasets\": [{\"ref-property-name\": \"referenceName\"}]},\n  \"metadata\": {\"spec-version\": \"1.5\"},\n  \"configuration-groups\": [\n    {\n      \"label\": \"Kafka Configuration\",\n      \"properties\": [\n        {\n          \"widget-type\": \"textbox\",\n          \"name\": \"referenceName\",\n          \"label\": \"Reference Name\"\n        },\n        {\n          \"widget-type\": \"csv\",\n          \"name\": \"brokers\",\n          \"label\": \"Kafka Brokers\",\n          \"widget-attributes\": {\"delimiter\": \",\"}\n        },\n        {\n          \"widget-type\": \"connection-browser\",\n          \"widget-category\": \"plugin\",\n          \"widget-attributes\": {\n            \"label\": \"Browse\",\n            \"connectionType\": \"KAFKA\"\n          }\n        },\n        {\n          \"widget-type\": \"textbox\",\n          \"name\": \"topic\",\n          \"label\": \"Kafka Topic\"\n        },\n        {\n          \"widget-type\": \"csv\",\n          \"name\": \"partitions\",\n          \"label\": \"Topic Partitions\",\n          \"widget-attributes\": {\"delimiter\": \",\"}\n        },\n        {\n          \"widget-type\": \"select\",\n          \"name\": \"initialOffset\",\n          \"label\": \"Initial Offset\",\n          \"widget-attributes\": {\n            \"default\": \"Start from beginning\",\n            \"values\": [\n              \"Start from beginning\",\n              \"Start from last processed offset\",\n              \"Start from specific offset\"\n            ]\n          }\n        },\n        {\n          \"widget-type\": \"textbox\",\n          \"name\": \"defaultInitialOffset\",\n          \"label\": \"Default Initial Offset\"\n        },\n        {\n          \"widget-type\": \"keyvalue\",\n          \"name\": \"initialPartitionOffsets\",\n          \"label\": \"Initial Partition Offsets\",\n          \"widget-attributes\": {\n            \"key-placeholder\": \"Partition\",\n            \"value-placeholder\": \"Offset\",\n            \"showDelimiter\": \"false\"\n          }\n        },\n        {\n          \"widget-type\": \"textbox\",\n          \"name\": \"timeField\",\n          \"label\": \"Time Field\"\n        },\n        {\n          \"widget-type\": \"textbox\",\n          \"name\": \"keyField\",\n          \"label\": \"Key Field\"\n        },\n        {\n          \"widget-type\": \"textbox\",\n          \"name\": \"partitionField\",\n          \"label\": \"Partition Field\"\n        },\n        {\n          \"widget-type\": \"textbox\",\n          \"name\": \"offsetField\",\n          \"label\": \"Offset Field\"\n        },\n        {\n          \"widget-type\": \"textbox\",\n          \"name\": \"maxRatePerPartition\",\n          \"label\": \"Max Rate Per Partition\",\n          \"widget-attributes\": {\"default\": \"1000\"}\n        },\n        {\n          \"widget-type\": \"keyvalue\",\n          \"name\": \"kafkaProperties\",\n          \"label\": \"Additional Kafka Consumer Properties\",\n          \"widget-attributes\": {\n            \"key-placeholder\": \"Kafka consumer property\",\n            \"value-placeholder\": \"Kafka consumer property value\",\n            \"showDelimiter\": \"false\"\n          }\n        }\n      ]\n    },\n    {\n      \"label\": \"Format\",\n      \"properties\": [{\n        \"widget-type\": \"select\",\n        \"name\": \"format\",\n        \"label\": \"Format\",\n        \"widget-attributes\": {\n          \"default\": \"\",\n          \"values\": [\n            \"\",\n            \"avro\",\n            \"binary\",\n            \"clf\",\n            \"csv\",\n            \"grok\",\n            \"syslog\",\n            \"text\",\n            \"tsv\"\n          ]\n        }\n      }]\n    },\n    {\n      \"label\": \"Authentication\",\n      \"properties\": [\n        {\n          \"widget-type\": \"textbox\",\n          \"name\": \"principal\",\n          \"label\": \"Kerberos Principal\"\n        },\n        {\n          \"widget-type\": \"textbox\",\n          \"name\": \"keytabLocation\",\n          \"label\": \"Keytab Location\"\n        }\n      ]\n    }\n  ],\n  \"display-name\": \"Kafka Consumer\",\n  \"filters\": [{\n    \"condition\": {\"expression\": \"initialOffset == 'Start from specific offset'\"},\n    \"name\": \"getOffsetInput\",\n    \"show\": [{\n      \"name\": \"defaultInitialOffset\",\n      \"type\": \"property\"\n    }]\n  }]\n}",
    "widgets.Kafka-batchsink": "{\n  \"outputs\": [],\n  \"jump-config\": {\"datasets\": [{\"ref-property-name\": \"referenceName\"}]},\n  \"metadata\": {\"spec-version\": \"1.5\"},\n  \"configuration-groups\": [\n    {\n      \"label\": \"Connection\",\n      \"properties\": [\n        {\n          \"widget-type\": \"toggle\",\n          \"name\": \"useConnection\",\n          \"label\": \"Use Connection\",\n          \"widget-attributes\": {\n            \"default\": \"false\",\n            \"off\": {\n              \"label\": \"NO\",\n              \"value\": \"false\"\n            },\n            \"on\": {\n              \"label\": \"YES\",\n              \"value\": \"true\"\n            }\n          }\n        },\n        {\n          \"widget-type\": \"connection-select\",\n          \"name\": \"connection\",\n          \"label\": \"Connection\",\n          \"widget-attributes\": {\"connectionType\": \"Kafka\"}\n        },\n        {\n          \"widget-type\": \"hidden\",\n          \"name\": \"kafkaBrokers\",\n          \"label\": \"Kafka Brokers\",\n          \"widget-attributes\": {\"delimiter\": \",\"}\n        },\n        {\n          \"widget-type\": \"csv\",\n          \"name\": \"brokers\",\n          \"label\": \"Kafka Brokers\",\n          \"widget-attributes\": {\"delimiter\": \",\"}\n        }\n      ]\n    },\n    {\n      \"label\": \"Kafka Producer and Topic Config\",\n      \"properties\": [\n        {\n          \"widget-type\": \"textbox\",\n          \"name\": \"referenceName\",\n          \"label\": \"Reference Name\"\n        },\n        {\n          \"widget-type\": \"connection-browser\",\n          \"widget-category\": \"plugin\",\n          \"widget-attributes\": {\n            \"label\": \"Browse\",\n            \"connectionType\": \"KAFKA\"\n          }\n        },\n        {\n          \"widget-type\": \"textbox\",\n          \"name\": \"topic\",\n          \"label\": \"Kafka Topic\"\n        },\n        {\n          \"widget-type\": \"select\",\n          \"name\": \"async\",\n          \"label\": \"Is Async ?\",\n          \"widget-attributes\": {\n            \"default\": \"FALSE\",\n            \"values\": [\n              \"TRUE\",\n              \"FALSE\"\n            ]\n          }\n        },\n        {\n          \"widget-type\": \"select\",\n          \"name\": \"compressionType\",\n          \"label\": \"Compression type\",\n          \"widget-attributes\": {\n            \"default\": \"none\",\n            \"values\": [\n              \"none\",\n              \"gzip\",\n              \"snappy\"\n            ]\n          }\n        },\n        {\n          \"widget-type\": \"keyvalue\",\n          \"name\": \"kafkaProperties\",\n          \"label\": \"Additional Kafka Producer Properties\",\n          \"widget-attributes\": {\n            \"key-placeholder\": \"Kafka producer property\",\n            \"value-placeholder\": \"Kafka producer property value\",\n            \"showDelimiter\": \"false\"\n          }\n        }\n      ]\n    },\n    {\n      \"label\": \"Message Configuration\",\n      \"properties\": [\n        {\n          \"widget-type\": \"select\",\n          \"name\": \"format\",\n          \"label\": \"Message Format\",\n          \"widget-attributes\": {\n            \"default\": \"CSV\",\n            \"values\": [\n              \"CSV\",\n              \"JSON\"\n            ]\n          }\n        },\n        {\n          \"widget-type\": \"textbox\",\n          \"name\": \"key\",\n          \"label\": \"Message Key field\"\n        }\n      ]\n    },\n    {\n      \"label\": \"Authentication\",\n      \"properties\": [\n        {\n          \"widget-type\": \"textbox\",\n          \"name\": \"principal\",\n          \"label\": \"Kerberos Principal\"\n        },\n        {\n          \"widget-type\": \"textbox\",\n          \"name\": \"keytabLocation\",\n          \"label\": \"Keytab Location\"\n        }\n      ]\n    }\n  ],\n  \"display-name\": \"Kafka Producer\",\n  \"icon\": {\n    \"arguments\": {\"data\": \"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAYAAAAeP4ixAAAAAXNSR0IArs4c6QAAACBjSFJNAAB6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\\r\\nPGYAAAAASUVORK5C\"},\n    \"type\": \"inline\"\n  },\n  \"filters\": [\n    {\n      \"condition\": {\"expression\": \"useConnection == false\"},\n      \"name\": \"showConnectionProperties \",\n      \"show\": [{\n        \"name\": \"brokers\",\n        \"type\": \"property\"\n      }]\n    },\n    {\n      \"condition\": {\"expression\": \"useConnection == true\"},\n      \"name\": \"showConnectionId\",\n      \"show\": [{\n        \"name\": \"connection\",\n        \"type\": \"property\"\n      }]\n    }\n  ]\n}",
    "doc.KAFKASOURCE": "[![Build Status](https://travis-ci.org/hydrator/kafka-plugins.svg?branch=master)](https://travis-ci.org/hydrator/kafka-plugins) [![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n\nKafka Source\n===========\n\nKafka streaming source that emits a records with user specified schema.\n\n<img align=\"center\" src=\"kafka-source-plugin-config.png\"  width=\"400\" alt=\"plugin configuration\" />\n\nUsage Notes\n-----------\n\nKafka Streaming Source can be used to read events from a kafka topic. It uses kafka consumer [2.6 apis](https://kafka.apache.org/26/documentation.html) to read events from a kafka topic. Kafka Source converts incoming kafka events into cdap structured records which then can be used for further transformations.\n\nThe source provides capabilities to read from latest offset or from beginning or from the provided kafka offset. The plugin relies on Spark Streaming offset [storage capabilities](https://spark.apache.org/docs/latest/streaming-kafka-0-10-integration.html) to manager offsets and checkpoints.\n\nPlugin Configuration\n---------------------\n\n| Configuration | Required | Default | Description |\n| :------------ | :------: | :----- | :---------- |\n| **Kafka Brokers** | **Y** | N/A | List of Kafka brokers specified in host1:port1,host2:port2 form. |\n| **Kafka Topic** | **Y** | N/A | The Kafka topic to read from. |\n| **Topic Partition** | **N** | N/A | List of topic partitions to read from. If not specified, all partitions will be read.  |\n| **Default Initial Offset** | **N** | N/A | The default initial offset for all topic partitions. An offset of -2 means the smallest offset. An offset of -1 means the latest offset. Defaults to -1. Offsets are inclusive. If an offset of 5 is used, the message at offset 5 will be read. If you wish to set different initial offsets for different partitions, use the initialPartitionOffsets property. |\n| **Initial Partition Offsets** | **N** | N/A | The initial offset for each topic partition. If this is not specified, all partitions will use the same initial offset, which is determined by the defaultInitialOffset property. Any partitions specified in the partitions property, but not in this property will use the defaultInitialOffset. An offset of -2 means the smallest offset. An offset of -1 means the latest offset. Offsets are inclusive. If an offset of 5 is used, the message at offset 5 will be read. |\n| **Time Field** | **N** | N/A | Optional name of the field containing the read time of the batch. If this is not set, no time field will be added to output records. If set, this field must be present in the schema property and must be a long. |\n| **Key Field** | **N** | N/A | Optional name of the field containing the message key. If this is not set, no key field will be added to output records. If set, this field must be present in the schema property and must be bytes. |\n| **Partition Field** | **N** | N/A | Optional name of the field containing the partition the message was read from. If this is not set, no partition field will be added to output records. If set, this field must be present in the schema property and must be an int. |\n| **Offset Field** | **N** | N/A | Optional name of the field containing the partition offset the message was read from. If this is not set, no offset field will be added to output records. If set, this field must be present in the schema property and must be a long. |\n| **Format** | **N** | N/A | Optional format of the Kafka event message. Any format supported by CDAP is supported. For example, a value of 'csv' will attempt to parse Kafka payloads as comma-separated values. If no format is given, Kafka message payloads will be treated as bytes. |\n| **Kerberos Principal** | **N** | N/A | The kerberos principal used for the source when kerberos security is enabled for kafka. |\n| **Keytab Location** | **N** | N/A | The keytab location for the kerberos principal when kerberos security is enabled for kafka. |\n\n\nBuild\n-----\nTo build this plugin:\n\n```\n   mvn clean package\n```    \n\nThe build will create a .jar and .json file under the ``target`` directory.\nThese files can be used to deploy your plugins.\n\nDeployment\n----------\nYou can deploy your plugins using the CDAP CLI:\n\n    > load artifact <target/kafka-plugins-<version>.jar config-file <target/kafka-plugins<version>.json>\n\nFor example, if your artifact is named 'kafka-plugins-<version>':\n\n    > load artifact target/kafka-plugins-<version>.jar config-file target/kafka-plugins-<version>.json\n    \n## Mailing Lists\n\nCDAP User Group and Development Discussions:\n\n* `cdap-user@googlegroups.com <https://groups.google.com/d/forum/cdap-user>`\n\nThe *cdap-user* mailing list is primarily for users using the product to develop\napplications or building plugins for appplications. You can expect questions from \nusers, release announcements, and any other discussions that we think will be helpful \nto the users.\n\n## License and Trademarks\n\nCopyright Â© 2018 Cask Data, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except\nin compliance with the License. You may obtain a copy of the License at\n\nhttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software distributed under the \nLicense is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, \neither express or implied. See the License for the specific language governing permissions \nand limitations under the License.\n\nCask is a trademark of Cask Data, Inc. All rights reserved.\n\nApache, Apache HBase, and HBase are trademarks of The Apache Software Foundation. Used with\npermission. No endorsement by The Apache Software Foundation is implied by the use of these marks.      \n",
    "doc.Kafka-streamingsource": "# Kafka Streaming Source\n\n\nDescription\n-----------\nKafka streaming source. Emits a record with the schema specified by the user. If no schema\nis specified, it will emit a record with two fields: 'key' (nullable string) and 'message'\n(bytes). This plugin uses kafka 2.6 java apis.\n\n\nUse Case\n--------\nThis source is used whenever you want to read from Kafka. For example, you may want to read messages\nfrom Kafka and write them to a Table.\n\n\nProperties\n----------\n**referenceName:** This will be used to uniquely identify this source for lineage, annotating metadata, etc.\n\n**brokers:** List of Kafka brokers specified in host1:port1,host2:port2 form. (Macro-enabled)\n\n**topic:** The Kafka topic to read from. (Macro-enabled)\n\n**partitions:** List of topic partitions to read from. If not specified, all partitions will be read. (Macro-enabled)\n\n**defaultInitialOffset:** The default initial offset for all topic partitions.\nAn offset of -2 means the smallest offset. An offset of -1 means the latest offset. Defaults to -1.\nOffsets are inclusive. If an offset of 5 is used, the message at offset 5 will be read.\nIf you wish to set different initial offsets for different partitions, use the initialPartitionOffsets property. (Macro-enabled)\n\n**initialOffset:** The initial offset for all topic partitions. \nStart from beginning means the smallest offset will be set.\nStart from last processed offset means the latest offset will be set. Defaults to null. \nIf start from specific offset is selected default initial offset must be provided. \nIf you wish to set different initial offsets for different partitions, use the initialPartitionOffsets property.\n\n**initialPartitionOffsets:** The initial offset for each topic partition. If this is not specified,\nall partitions will use the same initial offset, which is determined by the defaultInitialOffset property.\nAny partitions specified in the partitions property, but not in this property will use the defaultInitialOffset.\nAn offset of -2 means the smallest offset. An offset of -1 means the latest offset.\nOffsets are inclusive. If an offset of 5 is used, the message at offset 5 will be read. (Macro-enabled)\n\n**schema:** Output schema of the source. If you would like the output records to contain a field with the\nKafka message key, the schema must include a field of type bytes or nullable bytes, and you must set the\nkeyField property to that field's name. Similarly, if you would like the output records to contain a field with\nthe timestamp of when the record was read, the schema must include a field of type long or nullable long, and you\nmust set the timeField property to that field's name. Any field that is not the timeField or keyField will be used\nin conjuction with the format to parse Kafka message payloads.\n\n**format:** Optional format of the Kafka event message. Any format supported by CDAP is supported.\nFor example, a value of 'csv' will attempt to parse Kafka payloads as comma-separated values.\nIf no format is given, Kafka message payloads will be treated as bytes.\n\n**timeField:** Optional name of the field containing the read time of the batch.\nIf this is not set, no time field will be added to output records.\nIf set, this field must be present in the schema property and must be a long.\n\n**keyField:** Optional name of the field containing the message key.\nIf this is not set, no key field will be added to output records.\nIf set, this field must be present in the schema property and must be bytes.\n\n**partitionField:** Optional name of the field containing the partition the message was read from.\nIf this is not set, no partition field will be added to output records.\nIf set, this field must be present in the schema property and must be an int.\n\n**offsetField:** Optional name of the field containing the partition offset the message was read from.\nIf this is not set, no offset field will be added to output records.\nIf set, this field must be present in the schema property and must be a long.\n\n**maxRatePerPartition:** Maximum number of records to read per second per partition. Defaults to 1000.\n\n**principal** The kerberos principal used for the source when kerberos security is enabled for kafka.\n\n**keytabLocation** The keytab location for the kerberos principal when kerberos security is enabled for kafka.\n\nExample\n-------\nThis example reads from the 'purchases' topic of a Kafka instance running\non brokers host1.example.com:9092 and host2.example.com:9092. The source will add\na time field named 'readTime' that contains a timestamp corresponding to the micro\nbatch when the record was read. It will also contain a field named 'key' which will have\nthe message key in it. It parses the Kafka messages using the 'csv' format\nwith 'user', 'item', 'count', and 'price' as the message schema.\n\n```json\n{\n    \"name\": \"Kafka\",\n    \"type\": \"streamingsource\",\n    \"properties\": {\n        \"topics\": \"purchases\",\n        \"brokers\": \"host1.example.com:9092,host2.example.com:9092\",\n        \"format\": \"csv\",\n        \"timeField\": \"readTime\",\n        \"keyField\": \"key\",\n        \"schema\": \"{\n            \\\"type\\\":\\\"record\\\",\n            \\\"name\\\":\\\"purchase\\\",\n            \\\"fields\\\":[\n                {\\\"name\\\":\\\"readTime\\\",\\\"type\\\":\\\"long\\\"},\n                {\\\"name\\\":\\\"key\\\",\\\"type\\\":\\\"bytes\\\"},\n                {\\\"name\\\":\\\"user\\\",\\\"type\\\":\\\"string\\\"},\n                {\\\"name\\\":\\\"item\\\",\\\"type\\\":\\\"string\\\"},\n                {\\\"name\\\":\\\"count\\\",\\\"type\\\":\\\"int\\\"},\n                {\\\"name\\\":\\\"price\\\",\\\"type\\\":\\\"double\\\"}\n            ]\n        }\"\n    }\n}\n```\n\nFor each Kafka message read, it will output a record with the schema:\n\n| field name  | type             |\n| ----------- | ---------------- |\n| readTime    | long             |\n| key         | bytes            |\n| user        | string           |\n| item        | string           |\n| count       | int              |\n| price       | double           |\n\nNote that the readTime field is not derived from the Kafka message, but from the time that the\nmessage was read.\n",
    "doc.Kafka-batchsink": "# Kafka Sink\n\n\nDescription\n-----------\nKafka sink that allows you to write events into CSV or JSON to kafka.\nPlugin has the capability to push the data to a Kafka topic. It can also be\nconfigured to partition events being written to kafka based on a configurable key. \nThe sink can also be configured to operate in sync or async mode and apply different\ncompression types to events. This plugin uses kafka 2.6 java apis.\n\n\nConfiguration\n-------------\n**Use Connection** Whether to use a connection. If a connection is used, you do not need to provide the credentials.\n\n**Connection** Name of the connection to use. Brokers information will be provided by the connection. You can also use the macro function ${conn(connection_name)}.\n\n**referenceName:** This will be used to uniquely identify this sink for lineage, annotating metadata, etc.\n\n**brokers:** List of Kafka brokers specified in host1:port1,host2:port2 form.\n\n**topic:** The Kafka topic to write to.\n\n**async:** Specifies whether writing the events to broker is *Asynchronous* or *Synchronous*.\n\n**compressionType** Compression type to be applied on message. It can be none, gzip or snappy. Default value is none\n\n**format:** Specifies the format of the event published to Kafka. It can be csv or json. Defualt value is csv.\n\n**kafkaProperties** Specifies additional kafka producer properties like acks, client.id as key and value pair.\n\n**key:** Specifies the input field that should be used as the key for the event published into Kafka. \nIt will use String partitioner to determine kafka event should go to which partition. Key field should be of type string.\n\n**principal** The kerberos principal used for the source when kerberos security is enabled for kafka.\n \n**keytabLocation** The keytab location for the kerberos principal when kerberos security is enabled for kafka.\n\n\nExample\n-------\nThis example writes structured record to kafka topic 'alarm' in asynchronous manner \nusing compression type 'gzip'. The written events will be written in csv format \nto kafka running at localhost. The Kafka partition will be decided based on the provided key 'ts'.\nAdditional properties like number of acknowledgements and client id can also be provided.\n\n```json\n{\n    \"name\": \"Kafka\",\n    \"type\": \"batchsink\",\n    \"properties\": {\n        \"referenceName\": \"Kafka\",\n        \"brokers\": \"localhost:9092\",\n        \"topic\": \"alarm\",\n        \"async\": \"FALSE\",\n        \"compressionType\": \"gzip\",\n        \"format\": \"CSV\",\n        \"kafkaProperties\": \"acks:2,client.id:myclient\",\n        \"key\": \"message\"\n    }\n}\n```\n",
    "doc.Kafka-connector": "# Kafka Connection\n\nDescription\n-----------\nUse this connection to access data in Kafka.\n\nProperties\n----------\n**Name:** Name of the connection. Connection names must be unique in a namespace.\n\n**Description:** Description of the connection.\n\n**kafkaBrokers:** List of Kafka brokers specified in host1:port1,host2:port2 form.\n\nPath of the connection\n----------------------\nTo browse, get a sample from, or get the specification for this connection through\n[Pipeline Microservices](https://cdap.atlassian.net/wiki/spaces/DOCS/pages/975929350/Pipeline+Microservices), the `path`\nproperty is required in the request body. It can be in the following form :\n\n1. `/{topic}`\n   This path indicates a topic. A topic is the only one that can be sampled. Browse on this path to return the specified topic.\n\n2. `/`\n   This path indicates the root. A root cannot be sampled. Browse on this path to get all the topics visible through this connection.\n",
    "widgets.KafkaAlerts-alertpublisher": "{\n  \"outputs\": [],\n  \"metadata\": {\"spec-version\": \"1.5\"},\n  \"configuration-groups\": [\n    {\n      \"label\": \"Kafka Alert Publisher Config\",\n      \"properties\": [\n        {\n          \"widget-type\": \"csv\",\n          \"name\": \"brokers\",\n          \"label\": \"Kafka Brokers\",\n          \"widget-attributes\": {\"delimiter\": \",\"}\n        },\n        {\n          \"widget-type\": \"textbox\",\n          \"name\": \"topic\",\n          \"label\": \"Kafka Topic\"\n        },\n        {\n          \"widget-type\": \"keyvalue\",\n          \"name\": \"producerProperties\",\n          \"label\": \"Additional Kafka Producer Properties\",\n          \"widget-attributes\": {\n            \"key-placeholder\": \"Kafka producer property\",\n            \"value-placeholder\": \"Kafka producer property value\",\n            \"showDelimiter\": \"false\"\n          }\n        }\n      ]\n    },\n    {\n      \"label\": \"Authentication\",\n      \"properties\": [\n        {\n          \"widget-type\": \"textbox\",\n          \"name\": \"principal\",\n          \"label\": \"Kerberos Principal\"\n        },\n        {\n          \"widget-type\": \"textbox\",\n          \"name\": \"keytabLocation\",\n          \"label\": \"Keytab Location\"\n        }\n      ]\n    }\n  ],\n  \"display-name\": \"Kafka Alert Publisher\",\n  \"icon\": {\n    \"arguments\": {\"data\": \"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAYAAAAeP4ixAAAAAXNSR0IArs4c6QAAACBjSFJNAAB6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\\r\\nPGYAAAAASUVORK5C\"},\n    \"type\": \"inline\"\n  }\n}",
    "doc.Kafka-alert-publisher": "# kafka-alert-plugin\n\n<a href=\"https://cdap-users.herokuapp.com/\"><img alt=\"Join CDAP community\" src=\"https://cdap-users.herokuapp.com/badge.svg?t=kafka-alert-plugin\"/><\/a> [![Build Status](https://travis-ci.org/hydrator/kafka-alert-plugin.svg?branch=master)](https://travis-ci.org/hydrator/kafka-alert-plugin) [![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0) []() <img src=\"https://cdap-users.herokuapp.com/assets/cm-available.svg\"/>\n\nKafka Alert Publisher that allows you to publish alerts to kafka as json objects. The plugin internally uses kafka producer apis to publish alerts. \nThe plugin allows to specify kafka topic to use for publishing and other additional kafka producer properties. \nThis plugin uses kafka 2.6 java apis.\n\nBuild\n-----\nTo build this plugin:\n\n```\n   mvn clean package\n```    \n\nThe build will create a .jar and .json file under the ``target`` directory.\nThese files can be used to deploy your plugins.\n\nDeployment\n----------\nYou can deploy your plugins using the CDAP CLI:\n\n    > load artifact <target/kafka-alert-plugin-<version>.jar config-file <target/kafka-alert-plugin<version>.json>\n\nFor example, if your artifact is named 'kafka-alert-plugin-<version>':\n\n    > load artifact target/kafka-alert-plugin-<version>.jar config-file target/kafka-alert-plugin-<version>.json\n    \n## Mailing Lists\n\nCDAP User Group and Development Discussions:\n\n* `cdap-user@googlegroups.com <https://groups.google.com/d/forum/cdap-user>`\n\nThe *cdap-user* mailing list is primarily for users using the product to develop\napplications or building plugins for appplications. You can expect questions from \nusers, release announcements, and any other discussions that we think will be helpful \nto the users.\n\n## IRC Channel\n\nCDAP IRC Channel: #cdap on irc.freenode.net\n\n\n## License and Trademarks\n\nCopyright Â© 2018 Cask Data, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except\nin compliance with the License. You may obtain a copy of the License at\n\nhttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software distributed under the \nLicense is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, \neither express or implied. See the License for the specific language governing permissions \nand limitations under the License.\n\nCask is a trademark of Cask Data, Inc. All rights reserved.\n\nApache, Apache HBase, and HBase are trademarks of The Apache Software Foundation. Used with\npermission. No endorsement by The Apache Software Foundation is implied by the use of these marks.  \n"
  },
  "parents": [
    "system:cdap-data-pipeline[6.7.0-SNAPSHOT,7.0.0-SNAPSHOT)",
    "system:cdap-data-streams[6.7.0-SNAPSHOT,7.0.0-SNAPSHOT)"
  ]
}